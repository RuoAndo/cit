{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209a8a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Episode: Finished after 11 steps\n",
      "1 Episode: Finished after 11 steps\n",
      "2 Episode: Finished after 11 steps\n",
      "3 Episode: Finished after 10 steps\n",
      "4 Episode: Finished after 9 steps\n",
      "5 Episode: Finished after 10 steps\n",
      "6 Episode: Finished after 9 steps\n",
      "7 Episode: Finished after 8 steps\n",
      "8 Episode: Finished after 10 steps\n",
      "9 Episode: Finished after 12 steps\n",
      "10 Episode: Finished after 12 steps\n",
      "11 Episode: Finished after 12 steps\n",
      "12 Episode: Finished after 11 steps\n",
      "13 Episode: Finished after 11 steps\n",
      "14 Episode: Finished after 12 steps\n",
      "15 Episode: Finished after 12 steps\n",
      "16 Episode: Finished after 11 steps\n",
      "17 Episode: Finished after 16 steps\n",
      "18 Episode: Finished after 11 steps\n",
      "19 Episode: Finished after 10 steps\n",
      "20 Episode: Finished after 10 steps\n",
      "21 Episode: Finished after 12 steps\n",
      "22 Episode: Finished after 12 steps\n",
      "23 Episode: Finished after 11 steps\n",
      "24 Episode: Finished after 9 steps\n",
      "25 Episode: Finished after 9 steps\n",
      "26 Episode: Finished after 9 steps\n",
      "27 Episode: Finished after 11 steps\n",
      "28 Episode: Finished after 9 steps\n",
      "29 Episode: Finished after 11 steps\n",
      "30 Episode: Finished after 25 steps\n",
      "31 Episode: Finished after 58 steps\n",
      "32 Episode: Finished after 103 steps\n",
      "33 Episode: Finished after 18 steps\n",
      "34 Episode: Finished after 14 steps\n",
      "35 Episode: Finished after 114 steps\n",
      "36 Episode: Finished after 30 steps\n",
      "37 Episode: Finished after 85 steps\n",
      "38 Episode: Finished after 36 steps\n",
      "39 Episode: Finished after 65 steps\n",
      "40 Episode: Finished after 39 steps\n",
      "41 Episode: Finished after 31 steps\n",
      "42 Episode: Finished after 26 steps\n",
      "43 Episode: Finished after 41 steps\n",
      "44 Episode: Finished after 45 steps\n",
      "45 Episode: Finished after 60 steps\n",
      "46 Episode: Finished after 69 steps\n",
      "47 Episode: Finished after 49 steps\n",
      "48 Episode: Finished after 24 steps\n",
      "49 Episode: Finished after 39 steps\n",
      "50 Episode: Finished after 54 steps\n",
      "51 Episode: Finished after 47 steps\n",
      "52 Episode: Finished after 32 steps\n",
      "53 Episode: Finished after 34 steps\n",
      "54 Episode: Finished after 91 steps\n",
      "55 Episode: Finished after 80 steps\n",
      "56 Episode: Finished after 28 steps\n",
      "57 Episode: Finished after 53 steps\n",
      "58 Episode: Finished after 65 steps\n",
      "59 Episode: Finished after 60 steps\n",
      "60 Episode: Finished after 26 steps\n",
      "61 Episode: Finished after 121 steps\n",
      "62 Episode: Finished after 71 steps\n",
      "63 Episode: Finished after 74 steps\n",
      "64 Episode: Finished after 80 steps\n",
      "66 Episode: Finished after 60 steps\n",
      "67 Episode: Finished after 118 steps\n",
      "69 Episode: Finished after 117 steps\n",
      "70 Episode: Finished after 88 steps\n",
      "72 Episode: Finished after 62 steps\n",
      "73 Episode: Finished after 74 steps\n",
      "76 Episode: Finished after 194 steps\n",
      "77 Episode: Finished after 173 steps\n",
      "79 Episode: Finished after 79 steps\n",
      "80 Episode: Finished after 71 steps\n",
      "82 Episode: Finished after 103 steps\n",
      "84 Episode: Finished after 80 steps\n",
      "85 Episode: Finished after 192 steps\n",
      "88 Episode: Finished after 108 steps\n",
      "90 Episode: Finished after 150 steps\n",
      "91 Episode: Finished after 136 steps\n",
      "92 Episode: Finished after 105 steps\n",
      "93 Episode: Finished after 118 steps\n",
      "97 Episode: Finished after 103 steps\n",
      "98 Episode: Finished after 149 steps\n",
      "99 Episode: Finished after 179 steps\n",
      "101 Episode: Finished after 154 steps\n",
      "102 Episode: Finished after 139 steps\n",
      "103 Episode: Finished after 170 steps\n",
      "108 Episode: Finished after 159 steps\n",
      "109 Episode: Finished after 149 steps\n",
      "110 Episode: Finished after 134 steps\n",
      "112 Episode: Finished after 136 steps\n",
      "113 Episode: Finished after 138 steps\n",
      "114 Episode: Finished after 141 steps\n",
      "115 Episode: Finished after 184 steps\n",
      "119 Episode: Finished after 192 steps\n",
      "121 Episode: Finished after 198 steps\n",
      "122 Episode: Finished after 194 steps\n",
      "123 Episode: Finished after 163 steps\n",
      "124 Episode: Finished after 173 steps\n",
      "125 Episode: Finished after 174 steps\n",
      "128 Episode: Finished after 152 steps\n",
      "129 Episode: Finished after 177 steps\n",
      "133 Episode: Finished after 161 steps\n",
      "134 Episode: Finished after 162 steps\n",
      "136 Episode: Finished after 198 steps\n",
      "140 Episode: Finished after 143 steps\n",
      "141 Episode: Finished after 171 steps\n",
      "142 Episode: Finished after 160 steps\n",
      "143 Episode: Finished after 170 steps\n",
      "145 Episode: Finished after 140 steps\n",
      "147 Episode: Finished after 180 steps\n",
      "148 Episode: Finished after 141 steps\n",
      "149 Episode: Finished after 186 steps\n",
      "150 Episode: Finished after 190 steps\n",
      "151 Episode: Finished after 146 steps\n",
      "152 Episode: Finished after 170 steps\n",
      "154 Episode: Finished after 147 steps\n",
      "155 Episode: Finished after 164 steps\n",
      "156 Episode: Finished after 186 steps\n",
      "157 Episode: Finished after 168 steps\n",
      "158 Episode: Finished after 187 steps\n",
      "160 Episode: Finished after 156 steps\n",
      "161 Episode: Finished after 174 steps\n",
      "172 Episode: Finished after 166 steps\n",
      "175 Episode: Finished after 131 steps\n",
      "177 Episode: Finished after 149 steps\n",
      "179 Episode: Finished after 181 steps\n",
      "181 Episode: Finished after 161 steps\n",
      "182 Episode: Finished after 167 steps\n",
      "186 Episode: Finished after 169 steps\n",
      "187 Episode: Finished after 159 steps\n",
      "190 Episode: Finished after 170 steps\n",
      "192 Episode: Finished after 191 steps\n",
      "195 Episode: Finished after 193 steps\n",
      "198 Episode: Finished after 200 steps\n",
      "üéâ 200„Çπ„ÉÜ„ÉÉ„ÉóÊàêÂäüÔºö„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥ÂèéÈå≤„Å∏\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "\n",
    "ENV = 'CartPole-v1'\n",
    "GAMMA = 0.99\n",
    "MAX_STEPS = 200\n",
    "NUM_EPISODES = 500\n",
    "BATCH_SIZE = 32\n",
    "CAPACITY = 10000\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "def save_gif(frames, filename=\"cartpole.gif\"):\n",
    "    imageio.mimsave(filename, frames, fps=30)\n",
    "    display(Image(filename=filename))\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.index = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.index] = Transition(*args)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_in, n_mid, n_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_mid)\n",
    "        self.fc2 = nn.Linear(n_mid, n_mid)\n",
    "        self.fc3 = nn.Linear(n_mid, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class Brain:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.num_actions = num_actions\n",
    "        self.memory = ReplayMemory(CAPACITY)\n",
    "        self.main_q = Net(num_states, 32, num_actions)\n",
    "        self.target_q = Net(num_states, 32, num_actions)\n",
    "        self.optimizer = optim.Adam(self.main_q.parameters(), lr=0.0001)\n",
    "\n",
    "    def decide_action(self, state, episode):\n",
    "        epsilon = 0.5 * (1 / (episode + 1))\n",
    "        if epsilon <= np.random.rand():\n",
    "            self.main_q.eval()\n",
    "            with torch.no_grad():\n",
    "                return self.main_q(state).max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            return torch.LongTensor([[random.randrange(self.num_actions)]])\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = Transition(*zip(*self.memory.sample(BATCH_SIZE)))\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "        non_final_mask = torch.tensor([s is not None for s in batch.next_state], dtype=torch.bool)\n",
    "        state_action_values = self.main_q(state_batch).gather(1, action_batch)\n",
    "        next_state_values = torch.zeros(BATCH_SIZE)\n",
    "        a_m = torch.zeros(BATCH_SIZE, dtype=torch.long)\n",
    "        a_m[non_final_mask] = self.main_q(non_final_next_states).detach().max(1)[1]\n",
    "        a_m_non_final = a_m[non_final_mask].view(-1, 1)\n",
    "        next_state_values[non_final_mask] = self.target_q(non_final_next_states).gather(1, a_m_non_final).detach().squeeze()\n",
    "        expected = reward_batch + GAMMA * next_state_values\n",
    "        loss = F.smooth_l1_loss(state_action_values, expected.unsqueeze(1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_q_network(self):\n",
    "        self.target_q.load_state_dict(self.main_q.state_dict())\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.brain = Brain(num_states, num_actions)\n",
    "\n",
    "    def get_action(self, state, episode):\n",
    "        return self.brain.decide_action(state, episode)\n",
    "\n",
    "    def memorize(self, *args):\n",
    "        self.brain.memory.push(*args)\n",
    "\n",
    "    def update_q_function(self):\n",
    "        self.brain.replay()\n",
    "\n",
    "    def update_target_q_function(self):\n",
    "        self.brain.update_target_q_network()\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV, render_mode=\"rgb_array\")\n",
    "        self.agent = Agent(self.env.observation_space.shape[0], self.env.action_space.n)\n",
    "\n",
    "    def run(self):\n",
    "        episode_10_list = np.zeros(10)\n",
    "        frames = []\n",
    "        episode_final = False\n",
    "\n",
    "        for episode in range(NUM_EPISODES):\n",
    "            observation, _ = self.env.reset()\n",
    "            state = torch.FloatTensor(observation).unsqueeze(0)\n",
    "\n",
    "            for step in range(MAX_STEPS):\n",
    "                if episode_final:\n",
    "                    frame = self.env.render()\n",
    "                    frames.append(frame)\n",
    "\n",
    "                action = self.agent.get_action(state, episode)\n",
    "                observation_next, reward, terminated, truncated, _ = self.env.step(action.item())\n",
    "                done = terminated or truncated\n",
    "\n",
    "                if done:\n",
    "                    state_next = None\n",
    "                    reward = torch.FloatTensor([1.0 if step + 1 >= 200 else -1.0])\n",
    "                else:\n",
    "                    reward = torch.FloatTensor([0.0])\n",
    "                    state_next = torch.FloatTensor(observation_next).unsqueeze(0)\n",
    "\n",
    "                self.agent.memorize(state, action, state_next, reward)\n",
    "                self.agent.update_q_function()\n",
    "                state = state_next\n",
    "\n",
    "                if done:\n",
    "                    print(f\"{episode} Episode: Finished after {step + 1} steps\")\n",
    "                    if step + 1 >= 200:\n",
    "                        print(\"üéâ 200„Çπ„ÉÜ„ÉÉ„ÉóÊàêÂäüÔºö„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥ÂèéÈå≤„Å∏\")\n",
    "                        episode_final = True\n",
    "                    if episode % 2 == 0:\n",
    "                        self.agent.update_target_q_function()\n",
    "                    break\n",
    "\n",
    "            if episode_final:\n",
    "                break\n",
    "\n",
    "        if frames:\n",
    "            save_gif(frames, \"cartpole.gif\")\n",
    "\n",
    "# ÂÆüË°å\n",
    "env = Environment()\n",
    "env.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
