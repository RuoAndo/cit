{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30261617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\flare\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.20.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\flare\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (3.0.1)\n",
      "ğŸ“– Generator Pre-Training\n",
      "Epoch 0, Loss: 4.4581\n",
      "Epoch 50, Loss: 0.0141\n",
      "Epoch 100, Loss: 0.0042\n",
      "Epoch 150, Loss: 0.0021\n",
      "Epoch 200, Loss: 0.0012\n",
      "Epoch 250, Loss: 0.0008\n",
      "\n",
      "ğŸ“– Discriminator Pre-Training\n",
      "Epoch 0, Loss: 2.7101\n",
      "Epoch 20, Loss: 0.0808\n",
      "Epoch 40, Loss: 2.8082\n",
      "Epoch 60, Loss: 5.5304\n",
      "Epoch 80, Loss: 0.0226\n",
      "\n",
      "ğŸ¯ Adversarial Training (RL)\n",
      "Epoch 0, G Loss: 0.1018\n",
      "Epoch 10, G Loss: 0.0874\n",
      "Epoch 20, G Loss: 0.1585\n",
      "Epoch 30, G Loss: 0.1208\n",
      "Epoch 40, G Loss: 0.0016\n",
      "Epoch 50, G Loss: 0.0005\n",
      "Epoch 60, G Loss: 0.0010\n",
      "Epoch 70, G Loss: 0.0074\n",
      "Epoch 80, G Loss: 0.0005\n",
      "Epoch 90, G Loss: 0.0002\n",
      "\n",
      "ğŸŒ¸ ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«\n",
      "ç”Ÿæˆæ–‡: ãæ˜¥ã‚„å²©ã«å²©ã«å²©ã«å²©\n",
      "ç”Ÿæˆæ–‡: é›†å²©ã«å²©ã«å²©ã«å²©ã«å²©\n",
      "ç”Ÿæˆæ–‡: æ°´ã•ã‚„å²©ã«å²©ã«å²©ã«å²©\n",
      "ç”Ÿæˆæ–‡: å¯ºã«é£Ÿé£Ÿé£Ÿé£Ÿé£Ÿé£Ÿé£Ÿé£Ÿ\n",
      "ç”Ÿæˆæ–‡: ãŸã•ã‚„å²©ã«å²©ã«å²©ã«å²©\n"
     ]
    }
   ],
   "source": [
    "# âœ… è¶…è»½é‡SeqGANï¼ˆæ—¥æœ¬èªç‰ˆï¼‰å®Œå…¨ç‰ˆ\n",
    "# Google Colabå¯¾å¿œ\n",
    "\n",
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "!pip install torch torchvision tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# ğŸŒ± ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ—¥æœ¬èªçŸ­æ–‡ï¼‰\n",
    "data = [\n",
    "    \"æ˜¥ã®æµ·ã²ã­ã‚‚ã™ã®ãŸã‚Šã®ãŸã‚Šã‹ãª\",\n",
    "    \"å¤æ± ã‚„è›™é£›ã³ã“ã‚€æ°´ã®éŸ³\",\n",
    "    \"æŸ¿é£Ÿãˆã°é˜ãŒé³´ã‚‹ãªã‚Šæ³•éš†å¯º\",\n",
    "    \"å±±è·¯æ¥ã¦ä½•ã‚„ã‚‰ã‚†ã‹ã—ã™ã¿ã‚Œè‰\",\n",
    "    \"å¤è‰ã‚„å…µã©ã‚‚ãŒå¤¢ã®è·¡\",\n",
    "    \"ç§‹æ·±ãéš£ã¯ä½•ã‚’ã™ã‚‹äººã\",\n",
    "    \"åæœˆã‚„æ± ã‚’ã‚ãã‚Šã¦å¤œã‚‚ã™ãŒã‚‰\",\n",
    "    \"é–‘ã•ã‚„å²©ã«ã—ã¿å…¥ã‚‹è‰ã®å£°\",\n",
    "    \"äº”æœˆé›¨ã‚’é›†ã‚ã¦æ—©ã—æœ€ä¸Šå·\",\n",
    "    \"è¡Œãæ˜¥ã‚„é³¥å•¼ãé­šã®ç›®ã¯æ³ª\"\n",
    "]\n",
    "\n",
    "chars = sorted(list(set(\"\".join(data))))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "def encode(text): return [char2idx[c] for c in text]\n",
    "def decode(indices): return \"\".join([idx2char[i] for i in indices])\n",
    "\n",
    "encoded_data = [torch.tensor(encode(sentence)) for sentence in data]\n",
    "\n",
    "# âš™ï¸ Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        logits = self.fc(out)\n",
    "        return logits, hidden\n",
    "    \n",
    "    def sample(self, start_token, length):\n",
    "        result = [start_token]\n",
    "        input = torch.tensor([[start_token]])\n",
    "        hidden = None\n",
    "        for _ in range(length - 1):\n",
    "            logits, hidden = self.forward(input, hidden)\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            result.append(next_token)\n",
    "            input = torch.tensor([[next_token]])\n",
    "        return result\n",
    "\n",
    "# âš™ï¸ Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_filters, filter_sizes):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (fs, embed_dim)) for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(1)  # (batch, 1, seq_len, emb_dim)\n",
    "        x = [torch.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [torch.max(t, dim=2)[0] for t in x]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        return self.sigmoid(self.fc(x))\n",
    "\n",
    "# ğŸŒ± ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–\n",
    "generator = Generator(vocab_size, 16, 32)\n",
    "discriminator = Discriminator(vocab_size, 16, 32, [2,3,4])\n",
    "\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.01)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "# ğŸ”¥ äº‹å‰å­¦ç¿’ï¼šGenerator\n",
    "print(\"ğŸ“– Generator Pre-Training\")\n",
    "for epoch in range(300):\n",
    "    for sentence in encoded_data:\n",
    "        inputs = sentence[:-1].unsqueeze(0)\n",
    "        targets = sentence[1:].unsqueeze(0)\n",
    "        logits, _ = generator(inputs)\n",
    "        loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n",
    "        g_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        g_optimizer.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ğŸ”¥ äº‹å‰å­¦ç¿’ï¼šDiscriminator\n",
    "print(\"\\nğŸ“– Discriminator Pre-Training\")\n",
    "real_label, fake_label = 1, 0\n",
    "for epoch in range(100):\n",
    "    for sentence in encoded_data:\n",
    "        real_data = sentence.unsqueeze(0)\n",
    "        fake_seq = generator.sample(random.choice(range(vocab_size)), len(sentence))\n",
    "        fake_data = torch.tensor([fake_seq])\n",
    "        \n",
    "        real_out = discriminator(real_data)\n",
    "        fake_out = discriminator(fake_data)\n",
    "        \n",
    "        real_loss = bce_loss(real_out, torch.ones_like(real_out)*real_label)\n",
    "        fake_loss = bce_loss(fake_out, torch.ones_like(fake_out)*fake_label)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "# ğŸ”¥ å¼·åŒ–å­¦ç¿’ï¼šAdversarial Training\n",
    "print(\"\\nğŸ¯ Adversarial Training (RL)\")\n",
    "for epoch in range(100):\n",
    "    for _ in range(len(data)):\n",
    "        start_token = random.choice(range(vocab_size))\n",
    "        fake_seq = generator.sample(start_token, 10)\n",
    "        fake_data = torch.tensor([fake_seq])\n",
    "        \n",
    "        reward = discriminator(fake_data).detach()\n",
    "        log_probs, _ = generator(fake_data[:,:-1])\n",
    "        log_probs = torch.log_softmax(log_probs, dim=-1)\n",
    "        selected_log_probs = log_probs.gather(2, fake_data[:,1:].unsqueeze(-1)).squeeze(-1)\n",
    "        loss = -torch.mean(selected_log_probs * reward)\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        g_optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, G Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ğŸŒ¸ ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ\n",
    "print(\"\\nğŸŒ¸ ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«\")\n",
    "for _ in range(5):\n",
    "    start_token = random.choice(range(vocab_size))\n",
    "    generated = generator.sample(start_token, 10)\n",
    "    print(\"ç”Ÿæˆæ–‡:\", decode(generated))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
