{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6561910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flare\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 11.0\n",
      "Episode 2: Total Reward = 12.0\n",
      "Episode 3: Total Reward = 10.0\n",
      "Episode 4: Total Reward = 10.0\n",
      "Episode 5: Total Reward = 10.0\n",
      "Episode 6: Total Reward = 9.0\n",
      "Episode 7: Total Reward = 8.0\n",
      "Episode 8: Total Reward = 10.0\n",
      "Episode 9: Total Reward = 9.0\n",
      "Episode 10: Total Reward = 10.0\n",
      "Episode 11: Total Reward = 8.0\n",
      "Episode 12: Total Reward = 10.0\n",
      "Episode 13: Total Reward = 9.0\n",
      "Episode 14: Total Reward = 11.0\n",
      "Episode 15: Total Reward = 10.0\n",
      "Episode 16: Total Reward = 8.0\n",
      "Episode 17: Total Reward = 10.0\n",
      "Episode 18: Total Reward = 10.0\n",
      "Episode 19: Total Reward = 8.0\n",
      "Episode 20: Total Reward = 10.0\n",
      "Episode 21: Total Reward = 10.0\n",
      "Episode 22: Total Reward = 9.0\n",
      "Episode 23: Total Reward = 9.0\n",
      "Episode 24: Total Reward = 10.0\n",
      "Episode 25: Total Reward = 10.0\n",
      "Episode 26: Total Reward = 11.0\n",
      "Episode 27: Total Reward = 10.0\n",
      "Episode 28: Total Reward = 8.0\n",
      "Episode 29: Total Reward = 8.0\n",
      "Episode 30: Total Reward = 10.0\n",
      "Episode 31: Total Reward = 10.0\n",
      "Episode 32: Total Reward = 9.0\n",
      "Episode 33: Total Reward = 9.0\n",
      "Episode 34: Total Reward = 9.0\n",
      "Episode 35: Total Reward = 8.0\n",
      "Episode 36: Total Reward = 10.0\n",
      "Episode 37: Total Reward = 8.0\n",
      "Episode 38: Total Reward = 8.0\n",
      "Episode 39: Total Reward = 9.0\n",
      "Episode 40: Total Reward = 10.0\n",
      "Episode 41: Total Reward = 9.0\n",
      "Episode 42: Total Reward = 9.0\n",
      "Episode 43: Total Reward = 10.0\n",
      "Episode 44: Total Reward = 9.0\n",
      "Episode 45: Total Reward = 8.0\n",
      "Episode 46: Total Reward = 9.0\n",
      "Episode 47: Total Reward = 11.0\n",
      "Episode 48: Total Reward = 9.0\n",
      "Episode 49: Total Reward = 9.0\n",
      "Episode 50: Total Reward = 10.0\n",
      "Episode 51: Total Reward = 9.0\n",
      "Episode 52: Total Reward = 9.0\n",
      "Episode 53: Total Reward = 10.0\n",
      "Episode 54: Total Reward = 9.0\n",
      "Episode 55: Total Reward = 9.0\n",
      "Episode 56: Total Reward = 8.0\n",
      "Episode 57: Total Reward = 10.0\n",
      "Episode 58: Total Reward = 9.0\n",
      "Episode 59: Total Reward = 8.0\n",
      "Episode 60: Total Reward = 10.0\n",
      "Episode 61: Total Reward = 10.0\n",
      "Episode 62: Total Reward = 9.0\n",
      "Episode 63: Total Reward = 9.0\n",
      "Episode 64: Total Reward = 9.0\n",
      "Episode 65: Total Reward = 10.0\n",
      "Episode 66: Total Reward = 10.0\n",
      "Episode 67: Total Reward = 9.0\n",
      "Episode 68: Total Reward = 9.0\n",
      "Episode 69: Total Reward = 9.0\n",
      "Episode 70: Total Reward = 9.0\n",
      "Episode 71: Total Reward = 11.0\n",
      "Episode 72: Total Reward = 10.0\n",
      "Episode 73: Total Reward = 9.0\n",
      "Episode 74: Total Reward = 9.0\n",
      "Episode 75: Total Reward = 10.0\n",
      "Episode 76: Total Reward = 10.0\n",
      "Episode 77: Total Reward = 9.0\n",
      "Episode 78: Total Reward = 10.0\n",
      "Episode 79: Total Reward = 10.0\n",
      "Episode 80: Total Reward = 9.0\n",
      "Episode 81: Total Reward = 10.0\n",
      "Episode 82: Total Reward = 9.0\n",
      "Episode 83: Total Reward = 9.0\n",
      "Episode 84: Total Reward = 10.0\n",
      "Episode 85: Total Reward = 10.0\n",
      "Episode 86: Total Reward = 8.0\n",
      "Episode 87: Total Reward = 10.0\n",
      "Episode 88: Total Reward = 8.0\n",
      "Episode 89: Total Reward = 10.0\n",
      "Episode 90: Total Reward = 9.0\n",
      "Episode 91: Total Reward = 9.0\n",
      "Episode 92: Total Reward = 8.0\n",
      "Episode 93: Total Reward = 10.0\n",
      "Episode 94: Total Reward = 9.0\n",
      "Episode 95: Total Reward = 10.0\n",
      "Episode 96: Total Reward = 10.0\n",
      "Episode 97: Total Reward = 9.0\n",
      "Episode 98: Total Reward = 9.0\n",
      "Episode 99: Total Reward = 10.0\n",
      "Episode 100: Total Reward = 10.0\n",
      "Episode 101: Total Reward = 10.0\n",
      "Episode 102: Total Reward = 9.0\n",
      "Episode 103: Total Reward = 10.0\n",
      "Episode 104: Total Reward = 9.0\n",
      "Episode 105: Total Reward = 10.0\n",
      "Episode 106: Total Reward = 9.0\n",
      "Episode 107: Total Reward = 8.0\n",
      "Episode 108: Total Reward = 10.0\n",
      "Episode 109: Total Reward = 9.0\n",
      "Episode 110: Total Reward = 9.0\n",
      "Episode 111: Total Reward = 10.0\n",
      "Episode 112: Total Reward = 10.0\n",
      "Episode 113: Total Reward = 9.0\n",
      "Episode 114: Total Reward = 10.0\n",
      "Episode 115: Total Reward = 9.0\n",
      "Episode 116: Total Reward = 9.0\n",
      "Episode 117: Total Reward = 9.0\n",
      "Episode 118: Total Reward = 10.0\n",
      "Episode 119: Total Reward = 9.0\n",
      "Episode 120: Total Reward = 10.0\n",
      "Episode 121: Total Reward = 9.0\n",
      "Episode 122: Total Reward = 10.0\n",
      "Episode 123: Total Reward = 9.0\n",
      "Episode 124: Total Reward = 9.0\n",
      "Episode 125: Total Reward = 9.0\n",
      "Episode 126: Total Reward = 11.0\n",
      "Episode 127: Total Reward = 9.0\n",
      "Episode 128: Total Reward = 9.0\n",
      "Episode 129: Total Reward = 10.0\n",
      "Episode 130: Total Reward = 9.0\n",
      "Episode 131: Total Reward = 10.0\n",
      "Episode 132: Total Reward = 9.0\n",
      "Episode 133: Total Reward = 10.0\n",
      "Episode 134: Total Reward = 10.0\n",
      "Episode 135: Total Reward = 9.0\n",
      "Episode 136: Total Reward = 9.0\n",
      "Episode 137: Total Reward = 10.0\n",
      "Episode 138: Total Reward = 10.0\n",
      "Episode 139: Total Reward = 8.0\n",
      "Episode 140: Total Reward = 10.0\n",
      "Episode 141: Total Reward = 10.0\n",
      "Episode 142: Total Reward = 9.0\n",
      "Episode 143: Total Reward = 10.0\n",
      "Episode 144: Total Reward = 9.0\n",
      "Episode 145: Total Reward = 9.0\n",
      "Episode 146: Total Reward = 9.0\n",
      "Episode 147: Total Reward = 8.0\n",
      "Episode 148: Total Reward = 9.0\n",
      "Episode 149: Total Reward = 10.0\n",
      "Episode 150: Total Reward = 10.0\n",
      "Episode 151: Total Reward = 9.0\n",
      "Episode 152: Total Reward = 10.0\n",
      "Episode 153: Total Reward = 10.0\n",
      "Episode 154: Total Reward = 9.0\n",
      "Episode 155: Total Reward = 9.0\n",
      "Episode 156: Total Reward = 9.0\n",
      "Episode 157: Total Reward = 9.0\n",
      "Episode 158: Total Reward = 10.0\n",
      "Episode 159: Total Reward = 9.0\n",
      "Episode 160: Total Reward = 10.0\n",
      "Episode 161: Total Reward = 10.0\n",
      "Episode 162: Total Reward = 9.0\n",
      "Episode 163: Total Reward = 8.0\n",
      "Episode 164: Total Reward = 8.0\n",
      "Episode 165: Total Reward = 10.0\n",
      "Episode 166: Total Reward = 11.0\n",
      "Episode 167: Total Reward = 9.0\n",
      "Episode 168: Total Reward = 9.0\n",
      "Episode 169: Total Reward = 9.0\n",
      "Episode 170: Total Reward = 9.0\n",
      "Episode 171: Total Reward = 10.0\n",
      "Episode 172: Total Reward = 8.0\n",
      "Episode 173: Total Reward = 10.0\n",
      "Episode 174: Total Reward = 10.0\n",
      "Episode 175: Total Reward = 10.0\n",
      "Episode 176: Total Reward = 10.0\n",
      "Episode 177: Total Reward = 9.0\n",
      "Episode 178: Total Reward = 9.0\n",
      "Episode 179: Total Reward = 8.0\n",
      "Episode 180: Total Reward = 9.0\n",
      "Episode 181: Total Reward = 9.0\n",
      "Episode 182: Total Reward = 8.0\n",
      "Episode 183: Total Reward = 10.0\n",
      "Episode 184: Total Reward = 11.0\n",
      "Episode 185: Total Reward = 9.0\n",
      "Episode 186: Total Reward = 9.0\n",
      "Episode 187: Total Reward = 9.0\n",
      "Episode 188: Total Reward = 10.0\n",
      "Episode 189: Total Reward = 9.0\n",
      "Episode 190: Total Reward = 10.0\n",
      "Episode 191: Total Reward = 9.0\n",
      "Episode 192: Total Reward = 10.0\n",
      "Episode 193: Total Reward = 8.0\n",
      "Episode 194: Total Reward = 9.0\n",
      "Episode 195: Total Reward = 10.0\n",
      "Episode 196: Total Reward = 9.0\n",
      "Episode 197: Total Reward = 10.0\n",
      "Episode 198: Total Reward = 9.0\n",
      "Episode 199: Total Reward = 9.0\n",
      "Episode 200: Total Reward = 10.0\n",
      "Episode 201: Total Reward = 9.0\n",
      "Episode 202: Total Reward = 11.0\n",
      "Episode 203: Total Reward = 9.0\n",
      "Episode 204: Total Reward = 10.0\n",
      "Episode 205: Total Reward = 10.0\n",
      "Episode 206: Total Reward = 9.0\n",
      "Episode 207: Total Reward = 10.0\n",
      "Episode 208: Total Reward = 10.0\n",
      "Episode 209: Total Reward = 10.0\n",
      "Episode 210: Total Reward = 9.0\n",
      "Episode 211: Total Reward = 10.0\n",
      "Episode 212: Total Reward = 10.0\n",
      "Episode 213: Total Reward = 10.0\n",
      "Episode 214: Total Reward = 10.0\n",
      "Episode 215: Total Reward = 9.0\n",
      "Episode 216: Total Reward = 9.0\n",
      "Episode 217: Total Reward = 9.0\n",
      "Episode 218: Total Reward = 9.0\n",
      "Episode 219: Total Reward = 10.0\n",
      "Episode 220: Total Reward = 9.0\n",
      "Episode 221: Total Reward = 9.0\n",
      "Episode 222: Total Reward = 10.0\n",
      "Episode 223: Total Reward = 8.0\n",
      "Episode 224: Total Reward = 9.0\n",
      "Episode 225: Total Reward = 10.0\n",
      "Episode 226: Total Reward = 10.0\n",
      "Episode 227: Total Reward = 9.0\n",
      "Episode 228: Total Reward = 10.0\n",
      "Episode 229: Total Reward = 10.0\n",
      "Episode 230: Total Reward = 9.0\n",
      "Episode 231: Total Reward = 10.0\n",
      "Episode 232: Total Reward = 10.0\n",
      "Episode 233: Total Reward = 10.0\n",
      "Episode 234: Total Reward = 9.0\n",
      "Episode 235: Total Reward = 10.0\n",
      "Episode 236: Total Reward = 10.0\n",
      "Episode 237: Total Reward = 11.0\n",
      "Episode 238: Total Reward = 10.0\n",
      "Episode 239: Total Reward = 9.0\n",
      "Episode 240: Total Reward = 10.0\n",
      "Episode 241: Total Reward = 9.0\n",
      "Episode 242: Total Reward = 10.0\n",
      "Episode 243: Total Reward = 9.0\n",
      "Episode 244: Total Reward = 8.0\n",
      "Episode 245: Total Reward = 9.0\n",
      "Episode 246: Total Reward = 10.0\n",
      "Episode 247: Total Reward = 9.0\n",
      "Episode 248: Total Reward = 9.0\n",
      "Episode 249: Total Reward = 10.0\n",
      "Episode 250: Total Reward = 9.0\n",
      "Episode 251: Total Reward = 9.0\n",
      "Episode 252: Total Reward = 9.0\n",
      "Episode 253: Total Reward = 10.0\n",
      "Episode 254: Total Reward = 8.0\n",
      "Episode 255: Total Reward = 10.0\n",
      "Episode 256: Total Reward = 10.0\n",
      "Episode 257: Total Reward = 9.0\n",
      "Episode 258: Total Reward = 8.0\n",
      "Episode 259: Total Reward = 10.0\n",
      "Episode 260: Total Reward = 9.0\n",
      "Episode 261: Total Reward = 9.0\n",
      "Episode 262: Total Reward = 10.0\n",
      "Episode 263: Total Reward = 9.0\n",
      "Episode 264: Total Reward = 9.0\n",
      "Episode 265: Total Reward = 9.0\n",
      "Episode 266: Total Reward = 8.0\n",
      "Episode 267: Total Reward = 9.0\n",
      "Episode 268: Total Reward = 9.0\n",
      "Episode 269: Total Reward = 10.0\n",
      "Episode 270: Total Reward = 8.0\n",
      "Episode 271: Total Reward = 10.0\n",
      "Episode 272: Total Reward = 10.0\n",
      "Episode 273: Total Reward = 10.0\n",
      "Episode 274: Total Reward = 10.0\n",
      "Episode 275: Total Reward = 8.0\n",
      "Episode 276: Total Reward = 10.0\n",
      "Episode 277: Total Reward = 9.0\n",
      "Episode 278: Total Reward = 9.0\n",
      "Episode 279: Total Reward = 8.0\n",
      "Episode 280: Total Reward = 9.0\n",
      "Episode 281: Total Reward = 9.0\n",
      "Episode 282: Total Reward = 9.0\n",
      "Episode 283: Total Reward = 10.0\n",
      "Episode 284: Total Reward = 10.0\n",
      "Episode 285: Total Reward = 10.0\n",
      "Episode 286: Total Reward = 10.0\n",
      "Episode 287: Total Reward = 9.0\n",
      "Episode 288: Total Reward = 10.0\n",
      "Episode 289: Total Reward = 10.0\n",
      "Episode 290: Total Reward = 10.0\n",
      "Episode 291: Total Reward = 11.0\n",
      "Episode 292: Total Reward = 8.0\n",
      "Episode 293: Total Reward = 10.0\n",
      "Episode 294: Total Reward = 10.0\n",
      "Episode 295: Total Reward = 8.0\n",
      "Episode 296: Total Reward = 10.0\n",
      "Episode 297: Total Reward = 8.0\n",
      "Episode 298: Total Reward = 9.0\n",
      "Episode 299: Total Reward = 10.0\n",
      "Episode 300: Total Reward = 9.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "# --- 環境とパラメータ設定 ---\n",
    "env = gym.make(\"CartPole-v1\", render_mode=None)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "gamma = 0.99\n",
    "lr = 0.01\n",
    "max_episodes = 300\n",
    "\n",
    "# --- Actor-Critic モデル定義 ---\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.fc = nn.Linear(state_dim, 128)\n",
    "        self.actor = nn.Linear(128, action_dim)\n",
    "        self.critic = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc(x))\n",
    "        return torch.softmax(self.actor(x), dim=-1), self.critic(x)\n",
    "\n",
    "model = ActorCritic(state_dim, action_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# --- 1エピソードの実行とログ収集 ---\n",
    "def train_one_episode():\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "\n",
    "    while not done:\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        probs, value = model(state_tensor)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "        action = dist.sample()\n",
    "\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        done = terminated or truncated\n",
    "\n",
    "        log_probs.append(dist.log_prob(action))\n",
    "        values.append(value)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    return log_probs, values, rewards\n",
    "\n",
    "# --- 学習ループ ---\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    log_probs, values, rewards = train_one_episode()\n",
    "\n",
    "    # 割引累積報酬（G）を計算\n",
    "    returns = []\n",
    "    G = 0\n",
    "    for r in reversed(rewards):\n",
    "        G = r + gamma * G\n",
    "        returns.insert(0, G)\n",
    "    returns = torch.tensor(returns, dtype=torch.float32)\n",
    "    values = torch.cat(values).squeeze()\n",
    "    log_probs = torch.stack(log_probs)\n",
    "\n",
    "    # 損失関数（Advantage）\n",
    "    advantage = returns - values.detach()\n",
    "    actor_loss = -torch.sum(log_probs * advantage)\n",
    "    critic_loss = nn.functional.mse_loss(values, returns)\n",
    "    loss = actor_loss + critic_loss\n",
    "\n",
    "    # 学習\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_reward = sum(rewards)\n",
    "    episode_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode+1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# --- アニメーションGIF生成 ---\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, max_episodes)\n",
    "ax.set_ylim(0, max(episode_rewards) * 1.1)\n",
    "line, = ax.plot([], [], lw=2)\n",
    "ax.set_title(\"PyTorch Actor-Critic: CartPole Learning\")\n",
    "ax.set_xlabel(\"Episode\")\n",
    "ax.set_ylabel(\"Total Reward\")\n",
    "xdata, ydata = [], []\n",
    "\n",
    "def update(frame):\n",
    "    xdata.append(frame)\n",
    "    ydata.append(episode_rewards[frame])\n",
    "    line.set_data(xdata, ydata)\n",
    "    return line,\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=range(len(episode_rewards)), blit=True)\n",
    "\n",
    "# --- GIF保存 ---\n",
    "ani.save(\"pytorch_actor_critic_learning.gif\", writer=PillowWriter(fps=10))\n",
    "# MP4で保存する場合（ffmpeg必要）：\n",
    "# ani.save(\"pytorch_actor_critic_learning.mp4\", writer=\"ffmpeg\", fps=10)\n",
    "\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
